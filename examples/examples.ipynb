{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "from pyfdm import methods\n",
    "from pyfdm.methods.fuzzy_sets import tfn\n",
    "from pyfdm import weights as f_weights\n",
    "from pyfdm import correlations as corrs\n",
    "from pyfdm.helpers import rank, generate_fuzzy_matrix\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.set_printoptions(suppress=True, precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input data\n",
    "\n",
    "To perform the multi-criteria evaluation, the decision matrix needs to be defined. It can be determined based on the real data, or created with the method provided in the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[8.19  8.552 8.816]\n",
      "  [5.268 9.057 9.856]\n",
      "  [6.944 8.37  9.395]\n",
      "  [7.608 8.032 9.499]]\n",
      "\n",
      " [[5.002 6.925 9.764]\n",
      "  [6.882 7.34  9.824]\n",
      "  [5.105 7.457 8.621]\n",
      "  [7.676 8.114 8.702]]\n",
      "\n",
      " [[6.38  9.049 9.774]\n",
      "  [6.096 6.245 9.609]\n",
      "  [5.489 8.717 9.455]\n",
      "  [5.011 6.228 7.522]]\n",
      "\n",
      " [[6.262 8.489 9.385]\n",
      "  [5.279 7.527 9.179]\n",
      "  [5.55  8.511 8.809]\n",
      "  [6.    8.231 8.874]]\n",
      "\n",
      " [[5.074 8.124 8.96 ]\n",
      "  [5.383 8.917 9.183]\n",
      "  [6.943 6.978 7.028]\n",
      "  [8.14  8.307 8.477]]]\n"
     ]
    }
   ],
   "source": [
    "# real data matrix\n",
    "real_matrix = np.array([\n",
    "    [[5, 7, 9], [5, 7, 9], [7, 9, 9]],\n",
    "    [[1, 3, 5], [3, 5, 7], [3, 5, 7]],\n",
    "    [[1, 1, 3], [1, 3, 5], [1, 3, 5]],\n",
    "    [[7, 9, 9], [7, 9, 9], [7, 9, 9]]\n",
    "])\n",
    "\n",
    "# randomly generated matrix\n",
    "# 5 alternatives\n",
    "# 4 criteria\n",
    "# lower bound = 5\n",
    "# upper bound = 10\n",
    "random_matrix = generate_fuzzy_matrix(5, 4, 5, 10)\n",
    "print(random_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization\n",
    "\n",
    "Data normalization allows for comparing numbers with each other. It converts the range of values that they fit in range between 0 and 1. Below the usage examples of methods implemented in the library. Types parameter is responsible for the direction of the normalization. One columns' values could be more preferred is the values are lower (`-1`), other one could be more preferred if the values are greater (`1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum \n",
      " [[[0.167 0.269 0.5  ]\n",
      "  [0.354 0.181 0.066]\n",
      "  [0.269 0.45  0.643]]\n",
      "\n",
      " [[0.033 0.115 0.278]\n",
      "  [0.59  0.254 0.085]\n",
      "  [0.115 0.25  0.5  ]]]\n",
      "Max \n",
      " [[[0.714 0.778 1.   ]\n",
      "  [0.286 0.222 0.   ]\n",
      "  [1.    1.    1.   ]]\n",
      "\n",
      " [[0.143 0.333 0.556]\n",
      "  [0.571 0.444 0.222]\n",
      "  [0.429 0.556 0.778]]]\n",
      "Linear \n",
      " [[[0.556 0.778 1.   ]\n",
      "  [0.111 0.143 0.2  ]\n",
      "  [0.778 1.    1.   ]]\n",
      "\n",
      " [[0.111 0.333 0.556]\n",
      "  [0.143 0.2   0.333]\n",
      "  [0.333 0.556 0.778]]]\n",
      "Minmax \n",
      " [[[ 0.5   0.75  1.  ]\n",
      "  [-0.    0.25  0.5 ]\n",
      "  [ 0.75  1.    1.  ]]\n",
      "\n",
      " [[ 0.    0.25  0.5 ]\n",
      "  [ 0.25  0.5   0.75]\n",
      "  [ 0.25  0.5   0.75]]]\n",
      "Vector \n",
      " [[[0.246 0.345 0.443]\n",
      "  [0.227 0.318 0.409]\n",
      "  [0.301 0.387 0.387]]\n",
      "\n",
      " [[0.049 0.148 0.246]\n",
      "  [0.136 0.227 0.318]\n",
      "  [0.129 0.215 0.301]]]\n",
      "SAW \n",
      " [[[0.556 0.778 1.   ]\n",
      "  [0.556 0.778 1.   ]\n",
      "  [0.778 1.    1.   ]]\n",
      "\n",
      " [[0.111 0.333 0.556]\n",
      "  [0.333 0.556 0.778]\n",
      "  [0.333 0.556 0.778]]]\n"
     ]
    }
   ],
   "source": [
    "normalizations = {\n",
    "    'Sum': tfn.normalizations.sum_normalization,\n",
    "    'Max': tfn.normalizations.max_normalization,\n",
    "    'Linear': tfn.normalizations.linear_normalization,\n",
    "    'Minmax': tfn.normalizations.minmax_normalization,\n",
    "    'Vector': tfn.normalizations.vector_normalization,\n",
    "    'SAW': tfn.normalizations.saw_normalization\n",
    "}\n",
    "\n",
    "types = np.array([1, -1, 1])\n",
    "\n",
    "for name, norm in normalizations.items():\n",
    "    nmatrix = norm(real_matrix, types)\n",
    "    print(f'{name} \\n {nmatrix[:2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance\n",
    "\n",
    "Distance is a measure that allows for indicating how far are two Triangular Fuzzy Numbers from each other. Different techniques have been developed to this end. The measures implemented in the library and their usage are presented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean: 3.0\n",
      "Weighted Euclidean: 1.8027756377319946\n",
      "Hamming: 5\n",
      "Weighted Hamming: 1.75\n",
      "Vertex: 1.7320508075688772\n",
      "Tran-Duckstein: 6.444444444444445\n",
      "L-R: 15.25\n",
      "Mahdavi: 1.7795130420052185\n"
     ]
    }
   ],
   "source": [
    "distances = {\n",
    "    'Euclidean': tfn.distances.euclidean_distance,\n",
    "    'Weighted Euclidean': tfn.distances.weighted_euclidean_distance,\n",
    "    'Hamming': tfn.distances.hamming_distance,\n",
    "    'Weighted Hamming': tfn.distances.weighted_hamming_distance,\n",
    "    'Vertex': tfn.distances.vertex_distance,\n",
    "    'Tran-Duckstein': tfn.distances.tran_duckstein_distance,\n",
    "    'L-R': tfn.distances.lr_distance,\n",
    "    'Mahdavi': tfn.distances.mahdavi_distance\n",
    "}\n",
    "\n",
    "x = np.array([2, 4, 5])\n",
    "y = np.array([1, 2, 3])\n",
    "\n",
    "for name, distance in distances.items():\n",
    "    d = distance(x, y)\n",
    "    print(f'{name}: {d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defuzzification\n",
    "\n",
    "To create a crisp ranking from the calculations performed in fuzzy environment, the obtained results should be defuzzified. Different techniques can be used to achieve this. The implemented methods and the example of their usage are presented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.6166666666666667\n",
      "Mean Area: 0.6000000000000001\n",
      "Graded Mean Average: 0.5833333333333334\n",
      "Weighted Mean: 0.6000000000000001\n"
     ]
    }
   ],
   "source": [
    "defuzzifications = {\n",
    "    'Mean': tfn.defuzzifications.mean_defuzzification,\n",
    "    'Mean Area': tfn.defuzzifications.mean_area_defuzzification,\n",
    "    'Graded Mean Average': tfn.defuzzifications.graded_mean_average_defuzzification,\n",
    "    'Weighted Mean': tfn.defuzzifications.weighted_mean_defuzzification                                                                                            \n",
    "}\n",
    "\n",
    "x = np.array([0.2, 0.55, 1.1])\n",
    "\n",
    "for name, defuzzy in defuzzifications.items():\n",
    "    d = defuzzy(x)\n",
    "    print(f'{name}: {d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights\n",
    "\n",
    "Criteria weights in multi-criteria problems are responsible for the importance of each parameter taken into consideration. The greater value assigned to the given criterion, the more important it will be in the assessment. For the purpose of weights definition, 4 methods from the library can be used. They are based on the statistical approach, which makes it possible to define the weights objectively, relying only on data diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal \n",
      " [[0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25]]\n",
      "Shannon Entropy \n",
      " [[0.248 0.262 0.262]\n",
      " [0.223 0.244 0.269]\n",
      " [0.237 0.252 0.235]\n",
      " [0.292 0.242 0.233]]\n",
      "STD \n",
      " [[0.308 0.222 0.179]\n",
      " [0.168 0.327 0.134]\n",
      " [0.208 0.208 0.396]\n",
      " [0.316 0.243 0.29 ]]\n",
      "Variance \n",
      " [[0.357 0.191 0.11 ]\n",
      " [0.106 0.413 0.062]\n",
      " [0.162 0.168 0.539]\n",
      " [0.374 0.229 0.289]]\n"
     ]
    }
   ],
   "source": [
    "weights_methods = {\n",
    "    'Equal': f_weights.equal_weights,\n",
    "    'Shannon Entropy' : f_weights.shannon_entropy_weights,\n",
    "    'STD': f_weights.standard_deviation_weights,\n",
    "    'Variance': f_weights.variance_weights\n",
    "}\n",
    "\n",
    "for name, method in weights_methods.items():\n",
    "    w = method(random_matrix)\n",
    "    print(f'{name} \\n {w}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation \n",
    "\n",
    "Different techniques from the group of Fuzzy Multi-Criteria Decision Analysis methods based on the Triangular Fuzzy Numbers can be used to assess the alternatives. The library contains 10 methods which can be used for this purpose. The examples of their application are presented below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision matrix\n",
    "\n",
    "Decision matrix represents the alternatives taken into consideration in the problem. Rows represent amount of alternatives, when columns describes the amount of criteria in the given problem. In the case presented below, we have 4 alternatives and 3 criteria. Moreover, all elements in the matrix should be represent as the Triangular Fuzzy Number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.array([\n",
    "    [[3, 4, 5],[4, 5, 6],[8, 9, 9]],\n",
    "    [[6, 7, 8],[4, 5, 6],[1, 2, 3]],\n",
    "    [[5, 6, 7],[2, 3, 4],[3, 4, 5]],\n",
    "    [[5, 6, 8],[2, 3, 4],[2, 3, 4]],\n",
    "    [[7, 8, 9],[7, 8, 9],[5, 6, 7]],\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights\n",
    "\n",
    "Weights can be defined objectively, as shown above with the given examples. However, the weights can be also defined directly based on expert knowledge. The library is implemented in a way to handle both crisp and fuzzy weights. Amount of weights should equal the criteria amount. They can be determined as follow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "Crisp weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "crisp_weights = np.array([0.4, 0.4, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "Triangular Fuzzy Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy_weights = np.array([[5, 7, 9], [7, 9, 9], [3, 5, 7]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criteria \n",
    "\n",
    "Criteria types are ment to reflect the direction of the values that is preferable in the problem. If the values for given criterion should be as big as possible, it is then a profit type and represent as `1` in the criteria types array. If the values should be as low as possible, it is then cost and should be represent as `-1` in the array. Moreover, the criteria types amount should equal amount of criteria in the decision matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = np.array([1, -1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fuzzy ARAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_aras = methods.fARAS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuzzy ARAS evaluation results with crisp and fuzzy weights  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crisp weights: [0.835 0.856 1.114 1.113 0.893]\n",
      "Fuzzy weights: [0.879 0.834 1.103 1.097 0.896]\n"
     ]
    }
   ],
   "source": [
    "print(f'Crisp weights: {f_aras(matrix, crisp_weights, types)}')\n",
    "print(f'Fuzzy weights: {f_aras(matrix, fuzzy_weights, types)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use ARAS method with different normalizations. Default, it is a `sum_normalization`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "aras = {\n",
    "    'Sum': methods.fARAS(tfn.normalizations.sum_normalization),\n",
    "    'Max': methods.fARAS(tfn.normalizations.max_normalization),\n",
    "    'Linear': methods.fARAS(tfn.normalizations.linear_normalization),\n",
    "    'Minmax': methods.fARAS(tfn.normalizations.minmax_normalization),\n",
    "    'Vector': methods.fARAS(tfn.normalizations.vector_normalization),\n",
    "    'SAW': methods.fARAS(tfn.normalizations.saw_normalization)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every normalization technique, we can perform assessment to obtain results and check if the type of normalization impacts the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for name, function in aras.items():\n",
    "    results[name] = function(matrix, fuzzy_weights, types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method      A1    A2    A3    A4    A5\n",
      "--------  ----  ----  ----  ----  ----\n",
      "Sum       0.88  0.83  1.1   1.1   0.9\n",
      "Max       0.98  0.87  1.06  1.04  0.89\n",
      "Linear    0.84  0.75  0.96  0.95  0.86\n",
      "Minmax    0.93  0.88  1.08  1.07  0.89\n",
      "Vector    0.64  0.56  0.48  0.47  0.85\n",
      "SAW       0.63  0.57  0.49  0.48  0.85\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([[name, *np.round(pref, 2)] for name, pref in results.items()],\n",
    "    headers=['Method'] + [f'A{i+1}' for i in range(10)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that different preferences are obtained with different normalizations. To check if the alternatives are ranked at the same place despite used normalization method, we can use the method from the library called `rank` which calculates ascending or descending position order based on given array. Since the ARAS method assess better alternatives with higher values, the order should be descending. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method      A1    A2    A3    A4    A5\n",
      "--------  ----  ----  ----  ----  ----\n",
      "Sum          4     5     1     2     3\n",
      "Max          3     5     1     2     4\n",
      "Linear       4     5     1     2     3\n",
      "Minmax       3     5     1     2     4\n",
      "Vector       2     3     4     5     1\n",
      "SAW          2     3     4     5     1\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([[name, *rank(pref, descending=True)] for name, pref in results.items()], \n",
    "    headers=['Method'] + [f'A{i+1}' for i in range(10)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen, that the ranking of alternatives is different for different normalization techniques. So the user should bear in mind that different methods can have impact the final result obtained within selected evaluation method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fuzzy CODAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.3   -27.223  28.96   23.976 -26.013]\n"
     ]
    }
   ],
   "source": [
    "f_codas = methods.fCODAS()\n",
    "print(f_codas(matrix, fuzzy_weights, types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the CODAS method we can also use different normalizations, as it was in the ARAS method. In addition, we can use different distance metrics to calculate the alternatives preference. Default the `distance_1` is the `euclidean_distance` and `distance_2` is the `hamming_distance`. While calling the fuzzy CODAS object, the `tau` parameter can be given, which is set to `0.02` as default. It is treated as the threshold parameter while calculating the relative assessment matrix. CODAS also assessed better alternatives with higher preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "codas = {\n",
    "    'Pair 1': methods.fCODAS(distance_1=tfn.distances.euclidean_distance, distance_2=tfn.distances.hamming_distance),\n",
    "    'Pair 2': methods.fCODAS(distance_1=tfn.distances.weighted_euclidean_distance, distance_2=tfn.distances.weighted_hamming_distance),\n",
    "    'Pair 3': methods.fCODAS(distance_1=tfn.distances.vertex_distance, distance_2=tfn.distances.lr_distance),\n",
    "    'Pair 4': methods.fCODAS(distance_1=tfn.distances.mahdavi_distance, distance_2=tfn.distances.lr_distance),\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when we defined the CODAS object with different pairs of distances, we can calculate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for name, function in codas.items():\n",
    "    results[name] = function(matrix, fuzzy_weights, types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method       A1       A2      A3      A4       A5\n",
      "--------  -----  -------  ------  ------  -------\n",
      "Pair 1     0.3    -27.22   28.96   23.98   -26.01\n",
      "Pair 2     0.55   -11.46   12.67    9.81   -11.57\n",
      "Pair 3    15.6   -161.23  148.14  142.27  -144.78\n",
      "Pair 4    15.8   -157.83  148.41  141.97  -148.34\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([[name, *np.round(pref, 2)] for name, pref in results.items()],\n",
    "    headers=['Method'] + [f'A{i+1}' for i in range(10)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see, that different distance metrics also have impact on the final results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fuzzy COPRAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.804 0.736 0.993 1.    0.824]\n"
     ]
    }
   ],
   "source": [
    "f_copras = methods.fCOPRAS()\n",
    "print(f_copras(matrix, fuzzy_weights, types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the case of the ARAS method, in the COPRAS technique, we can also modify the used normalization method. The `saw_normalization` is set as default. Similarly to previous methods, better alternatives are assessed with higher preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "copras = {\n",
    "    'Sum': methods.fCOPRAS(tfn.normalizations.sum_normalization),\n",
    "    'Max': methods.fCOPRAS(tfn.normalizations.max_normalization),\n",
    "    'Linear': methods.fCOPRAS(tfn.normalizations.linear_normalization),\n",
    "    'Minmax': methods.fCOPRAS(tfn.normalizations.minmax_normalization),\n",
    "    'Vector': methods.fCOPRAS(tfn.normalizations.vector_normalization),\n",
    "    'SAW': methods.fCOPRAS(tfn.normalizations.saw_normalization)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for name, function in copras.items():\n",
    "    results[name] = function(matrix, fuzzy_weights, types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method      A1    A2    A3    A4    A5\n",
      "--------  ----  ----  ----  ----  ----\n",
      "Sum       0.7   0.69  0.59  0.61  1\n",
      "Max       1     0.88  0.92  0.93  0\n",
      "Linear    0.73  0.67  0.59  0.59  1\n",
      "Minmax    0.97  0.93  0.94  1     1\n",
      "Vector    0.81  0.71  1     1     0.79\n",
      "SAW       0.8   0.74  0.99  1     0.82\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([[name, *np.round(pref, 2)] for name, pref in results.items()],\n",
    "    headers=['Method'] + [f'A{i+1}' for i in range(10)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fuzzy EDAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.691 0.292 0.698 0.74  0.468]\n"
     ]
    }
   ],
   "source": [
    "f_edas = methods.fEDAS()\n",
    "print(f_edas(matrix, fuzzy_weights, types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of using the fuzzy EDAS method, we can modify the used defuzzification technique. Default, the fEDAS method has set the defuzzification to the `mean_defuzzification`. EDAS also evaluate better alternatives with higher preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "edas = {\n",
    "    'Mean': methods.fEDAS(defuzzify=tfn.defuzzifications.mean_defuzzification),\n",
    "    'Mean Area': methods.fEDAS(defuzzify=tfn.defuzzifications.mean_area_defuzzification),\n",
    "    'Graded Mean Average': methods.fEDAS(defuzzify=tfn.defuzzifications.graded_mean_average_defuzzification),\n",
    "    'Weighted Mean': methods.fEDAS(defuzzify=tfn.defuzzifications.weighted_mean_defuzzification)                                                                                            \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fEDAS object definition, we can calculate the results based on using different defuzzification methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for name, function in edas.items():\n",
    "    results[name] = function(matrix, fuzzy_weights, types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method                 A1    A2    A3    A4    A5\n",
      "-------------------  ----  ----  ----  ----  ----\n",
      "Mean                 0.69  0.29  0.7   0.74  0.47\n",
      "Mean Area            0.71  0.3   0.72  0.65  0.45\n",
      "Graded Mean Average  0.73  0.31  0.75  0.67  0.42\n",
      "Weighted Mean        0.71  0.3   0.72  0.65  0.45\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([[name, *np.round(pref, 2)] for name, pref in results.items()],\n",
    "    headers=['Method'] + [f'A{i+1}' for i in range(10)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be noticed that the results are highly similar while using different methods to defuzzify fuzzy numbers and obtain crisp values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fuzzy MABAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.061 -0.644  1.82   1.695 -0.549]\n"
     ]
    }
   ],
   "source": [
    "f_mabac = methods.fMABAC()\n",
    "print(f_mabac(matrix, fuzzy_weights, types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While using the fuzzy MABAC method, the normalization and defuzzification methods can be adjusted. Default, normalization is set to `minmax_normalization` and defuzzify to `mean_defuzzification`. MABAC classify better alternatives with higher preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mabac = {\n",
    "    'Sum': methods.fMABAC(tfn.normalizations.sum_normalization),\n",
    "    'Max': methods.fMABAC(tfn.normalizations.max_normalization),\n",
    "    'Linear': methods.fMABAC(tfn.normalizations.linear_normalization),\n",
    "    'Minmax': methods.fMABAC(tfn.normalizations.minmax_normalization),\n",
    "    'Vector': methods.fMABAC(tfn.normalizations.vector_normalization),\n",
    "    'SAW': methods.fMABAC(tfn.normalizations.saw_normalization)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for name, function in mabac.items():\n",
    "    results[name] = function(matrix, fuzzy_weights, types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method       A1     A2     A3     A4     A5\n",
      "--------  -----  -----  -----  -----  -----\n",
      "Sum       -0.36  -0.52   0.61   0.6   -0.08\n",
      "Max        0.35  -0.79   1.57   1.34  -0.77\n",
      "Linear    -0.19  -1.49   1.53   1.31   0.16\n",
      "Minmax    -0.06  -0.64   1.82   1.7   -0.55\n",
      "Vector     0.43  -0.31  -0.93  -1.06   2.17\n",
      "SAW        0.79  -0.5   -2.02  -2.25   5.27\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([[name, *np.round(pref, 2)] for name, pref in results.items()],\n",
    "    headers=['Method'] + [f'A{i+1}' for i in range(10)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we can see, that different techniques used in the assessment have impact on the final result from the fuzzy MCDA method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fuzzy MAIRCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.039 3.193 3.315 3.337 2.683]\n"
     ]
    }
   ],
   "source": [
    "f_mairca = methods.fMAIRCA()\n",
    "print(f_mairca(matrix, fuzzy_weights, types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuzzy MAIRCA method allows for adjusting the parameters responsible for the normalization and the distance measures. Default settings covers the `vector_normalization` and the `vertex_distance`. MAIRCA assigns higher preference values to better classified alternatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mairca = {\n",
    "    'Euclidean': methods.fMAIRCA(distance=tfn.distances.euclidean_distance),\n",
    "    'Weighted Euclidean': methods.fMAIRCA(distance=tfn.distances.weighted_euclidean_distance),\n",
    "    'Hamming': methods.fMAIRCA(distance=tfn.distances.hamming_distance),\n",
    "    'Weighted Hamming': methods.fMAIRCA(distance=tfn.distances.weighted_hamming_distance),\n",
    "    'Vertex': methods.fMAIRCA(distance=tfn.distances.vertex_distance),\n",
    "    'Tran-Duckstein': methods.fMAIRCA(distance=tfn.distances.tran_duckstein_distance),\n",
    "    'L-R': methods.fMAIRCA(distance=tfn.distances.lr_distance),\n",
    "    'Mahdavi': methods.fMAIRCA(distance=tfn.distances.mahdavi_distance)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for name, function in mairca.items():\n",
    "    results[name] = function(matrix, fuzzy_weights, types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method                 A1     A2     A3     A4    A5\n",
      "------------------  -----  -----  -----  -----  ----\n",
      "Euclidean            5.26   5.53   5.74   5.78  4.65\n",
      "Weighted Euclidean   3.05   3.21   3.34   3.37  2.7\n",
      "Hamming              8.96   9.41   9.78   9.85  7.91\n",
      "Weighted Hamming     3.01   3.17   3.3    3.33  2.67\n",
      "Vertex               3.04   3.19   3.31   3.34  2.68\n",
      "Tran-Duckstein       5.53   5.75   6.42   6.52  4.08\n",
      "L-R                 13.32  13.9   15.49  15.72  9.8\n",
      "Mahdavi              3.04   3.2    3.32   3.35  2.69\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([[name, *np.round(pref, 2)] for name, pref in results.items()],\n",
    "    headers=['Method'] + [f'A{i+1}' for i in range(10)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fuzzy MOORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.403 0.707 1.641 1.573 0.931]\n"
     ]
    }
   ],
   "source": [
    "f_moora = methods.fMOORA()\n",
    "print(f_moora(matrix, fuzzy_weights, types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuzzy MOORA assigns higher preferences to better alternatives. It allows for the modification of the normalization technique, and the default method is set to `vector_normalization`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "moora = {\n",
    "    'Sum': methods.fMOORA(tfn.normalizations.sum_normalization),\n",
    "    'Max': methods.fMOORA(tfn.normalizations.max_normalization),\n",
    "    'Linear': methods.fMOORA(tfn.normalizations.linear_normalization),\n",
    "    'Minmax': methods.fMOORA(tfn.normalizations.minmax_normalization),\n",
    "    'Vector': methods.fMOORA(tfn.normalizations.vector_normalization),\n",
    "    'SAW': methods.fMOORA(tfn.normalizations.saw_normalization)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for name, function in moora.items():\n",
    "    results[name] = function(matrix, fuzzy_weights, types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method      A1    A2    A3    A4     A5\n",
      "--------  ----  ----  ----  ----  -----\n",
      "Sum       2.36  2.22  2.41  2.54   3.49\n",
      "Max       6.11  4.88  3.57  3.63  11\n",
      "Linear    5.18  3.85  1.22  1.23   8.37\n",
      "Minmax    2.16  1.66  2.03  2.5    8.54\n",
      "Vector    1.4   0.71  1.64  1.57   0.93\n",
      "SAW       3.97  2.68  4.74  4.66   3.27\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([[name, *np.round(pref, 2)] for name, pref in results.items()],\n",
    "    headers=['Method'] + [f'A{i+1}' for i in range(10)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fuzzy OCRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.283  0.     9.317  7.306  3.433]\n"
     ]
    }
   ],
   "source": [
    "f_ocra = methods.fOCRA()\n",
    "print(f_ocra(matrix, fuzzy_weights, types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OCRA has one parameter that can be changed during the evaluation. It is the defuzzification method, which default is set to `mean_defuzzification`. OCRA also assess better alternatives with higher preference values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocra = {\n",
    "    'Mean': methods.fOCRA(defuzzify=tfn.defuzzifications.mean_defuzzification),\n",
    "    'Mean Area': methods.fOCRA(defuzzify=tfn.defuzzifications.mean_area_defuzzification),\n",
    "    'Graded Mean Average': methods.fOCRA(defuzzify=tfn.defuzzifications.graded_mean_average_defuzzification),\n",
    "    'Weighted Mean': methods.fOCRA(defuzzify=tfn.defuzzifications.weighted_mean_defuzzification)                                                                                            \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for name, function in ocra.items():\n",
    "    results[name] = function(matrix, fuzzy_weights, types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method                  A1    A2    A3    A4    A5\n",
      "-------------------  -----  ----  ----  ----  ----\n",
      "Mean                 12.28     0  9.32  7.31  3.43\n",
      "Mean Area            12.28     0  9.3   7.17  3.26\n",
      "Graded Mean Average  12.27     0  9.28  7.03  3.09\n",
      "Weighted Mean        12.28     0  9.3   7.17  3.26\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([[name, *np.round(pref, 2)] for name, pref in results.items()],\n",
    "    headers=['Method'] + [f'A{i+1}' for i in range(10)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fuzzy TOPSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.564 0.565 0.552 0.551 0.562]\n"
     ]
    }
   ],
   "source": [
    "f_topsis = methods.fTOPSIS()\n",
    "print(f_topsis(matrix, fuzzy_weights, types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOPSIS technique allows for adjusting the parameters responsible for the normalization and the distance calculation. Default methods are set to `linear_normalization` and `vertex_distance`. TOPSIS assures, that better alternatives have higher preferences values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "topsis = {\n",
    "    'Sum': methods.fTOPSIS(tfn.normalizations.sum_normalization),\n",
    "    'Max': methods.fTOPSIS(tfn.normalizations.max_normalization),\n",
    "    'Linear': methods.fTOPSIS(tfn.normalizations.linear_normalization),\n",
    "    'Minmax': methods.fTOPSIS(tfn.normalizations.minmax_normalization),\n",
    "    'Vector': methods.fTOPSIS(tfn.normalizations.vector_normalization),\n",
    "    'SAW': methods.fTOPSIS(tfn.normalizations.saw_normalization)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for name, function in topsis.items():\n",
    "    results[name] = function(matrix, fuzzy_weights, types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method      A1    A2    A3    A4    A5\n",
      "--------  ----  ----  ----  ----  ----\n",
      "Sum       0.67  0.61  0.61  0.59  0.64\n",
      "Max       0.57  0.57  0.56  0.56  0.52\n",
      "Linear    0.56  0.57  0.55  0.55  0.56\n",
      "Minmax    0.56  0.55  0.55  0.55  0.56\n",
      "Vector    0.65  0.62  0.68  0.66  0.61\n",
      "SAW       0.56  0.56  0.57  0.57  0.54\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([[name, *np.round(pref, 2)] for name, pref in results.items()],\n",
    "    headers=['Method'] + [f'A{i+1}' for i in range(10)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fuzzy VIKOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S: [7.696 8.478 5.966 6.382 8.454]\n",
      "R: [5.    4.406 3.344 3.781 6.214]\n",
      "Q: [0.156 0.141 0.003 0.043 0.255]\n"
     ]
    }
   ],
   "source": [
    "f_vikor = methods.fVIKOR()\n",
    "res = f_vikor(matrix, fuzzy_weights, types)\n",
    "print(f'S: {res[0]}')\n",
    "print(f'R: {res[1]}')\n",
    "print(f'Q: {res[2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIKOR method is characterized by returning three assessment vectors (S, R, Q). The difference between them lays in the way how they are calculated in the final phase of the evaluation. The VIKOR method performance can be adjusted with the defuzzification method, and the default settings for this parameter is `mean_area_defuzzification`. Moreover, while calling the fVIKOR object, the `v` parameter can be given, which translates how the weight of the strategy will behave. It is set to `0.5` as default. VIKOR ranking can be calculated by sorting the preferences in the ascending order, so in the `rank` method, the parameter should be sey as `descending=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vikor = {\n",
    "    'Mean': methods.fVIKOR(defuzzify=tfn.defuzzifications.mean_defuzzification),\n",
    "    'Mean Area': methods.fVIKOR(defuzzify=tfn.defuzzifications.mean_area_defuzzification),\n",
    "    'Graded Mean Average': methods.fVIKOR(defuzzify=tfn.defuzzifications.graded_mean_average_defuzzification),\n",
    "    'Weighted Mean': methods.fVIKOR(defuzzify=tfn.defuzzifications.weighted_mean_defuzzification)                                                                                            \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for name, function in vikor.items():\n",
    "    results[name] = function(matrix, fuzzy_weights, types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method                 A1    A2    A3    A4    A5\n",
      "-------------------  ----  ----  ----  ----  ----\n",
      "Mean                 7.85  8.6   6.13  6.48  8.5\n",
      "Mean Area            7.7   8.48  5.97  6.38  8.45\n",
      "Graded Mean Average  7.54  8.36  5.8   6.28  8.4\n",
      "Weighted Mean        7.7   8.48  5.97  6.38  8.45\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([[name, *np.round(pref[0], 2)] for name, pref in results.items()],\n",
    "    headers=['Method'] + [f'A{i+1}' for i in range(10)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation\n",
    "\n",
    "Correlation coefficients can be used to indicate the results similarity. They are based on preference or ranking comparison obtained from the multi-criteria assessment. In the library there are available 4 different measures and the example of their usage is presented below. The `pearson_coef` and `spearman_coef` are ment to be used to compare the preference values, while `weighted_spearman_coef` and `ws_rank_similarity_coef` can be used to compare rankings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "Similar preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman: 0.9588593677597358\n",
      "Pearson: 0.9588593677597358\n"
     ]
    }
   ],
   "source": [
    "x = np.array([0.69, 0.53, 0.76, 0.81, 0.8])\n",
    "y = np.array([0.66, 0.54, 0.71, 0.84, 0.77])\n",
    "\n",
    "print(f'Spearman: {corrs.spearman_coef(x, y)}')\n",
    "print(f'Pearson: {corrs.pearson_coef(x, y)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "Different preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman: 0.225511293634533\n",
      "Pearson: 0.225511293634533\n"
     ]
    }
   ],
   "source": [
    "x = np.array([0.75, 0.39, 0.86, 0.51, 0.63])\n",
    "y = np.array([0.66, 0.54, 0.71, 0.84, 0.77])\n",
    "\n",
    "print(f'Spearman: {corrs.spearman_coef(x, y)}')\n",
    "print(f'Pearson: {corrs.pearson_coef(x, y)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3\n",
    "Similar rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Spearman: 0.85\n",
      "WS rank similarity: 0.7916666666666667\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([2, 1, 3, 4, 5])\n",
    "\n",
    "print(f'Weighted Spearman: {corrs.weighted_spearman_coef(x, y)}')\n",
    "print(f'WS rank similarity: {corrs.ws_rank_similarity_coef(x, y)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4\n",
    "Different rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Spearman: 0.050000000000000044\n",
      "WS rank similarity: 0.46354166666666663\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([4, 2, 1, 5, 3])\n",
    "\n",
    "print(f'Weighted Spearman: {corrs.weighted_spearman_coef(x, y)}')\n",
    "print(f'WS rank similarity: {corrs.ws_rank_similarity_coef(x, y)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eabca979b0553fa6d87e9a00c352604d3b703d4afc9641643dd42376492b80f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
